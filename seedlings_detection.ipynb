{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is about detecting rice seedling from the input image.\n",
    "@author Hsin-Yi Yang\n",
    "@acknowledgement All of the images used in the research were provided by GEOSAT Aerospace & Technology Inc.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from skimage import morphology\n",
    "from skimage.future import graph\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_ubyte, img_as_float\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import rank\n",
    "\n",
    "def imgResize(image,dsRatio):\n",
    "    dsImg = cv2.resize(image, (int(len(image[0])*dsRatio), int(len(image)*dsRatio)), interpolation=cv2.INTER_AREA)\n",
    "    return dsImg\n",
    "\n",
    "def normalize(matrix):\n",
    "    matrix = 255 * (matrix - matrix.min()) / (matrix.max() - matrix.min())\n",
    "    matrix = matrix.astype(np.uint8)\n",
    "    return matrix\n",
    "\n",
    "def complement(img):\n",
    "    return 255-img\n",
    "\n",
    "def calcTGI(B, G, R):\n",
    "    blue = img_as_float(B)\n",
    "    green = img_as_float(G)\n",
    "    red = img_as_float(R)\n",
    "    TGI = green - 0.39*red - 0.61*blue\n",
    "    TGI = normalize(TGI)\n",
    "    return TGI\n",
    "\n",
    "def calcVARI(B, G, R):\n",
    "    blue = img_as_float(B)\n",
    "    green = img_as_float(G)\n",
    "    red = img_as_float(R)\n",
    "    fraction = green - red\n",
    "    denominator = (green - red)/(green + red - blue)\n",
    "    VARI = np.divide(fraction, denominator, out=np.zeros_like(green), where=denominator!=0)\n",
    "    VARI = normalize(VARI)\n",
    "    return VARI    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"label with rag\"\"\"\n",
    "inputpath = \"./input/\"\n",
    "inputfiles = [file for file in os.listdir(inputpath) if file.endswith('.JPG')]\n",
    "inputfiles.sort()\n",
    "outputpath = \"./output/\"\n",
    "\n",
    "datasetpath = \"./dataset/mask/\"\n",
    "datasetfiles = [file for file in os.listdir(datasetpath) if file.endswith('.jpg')]\n",
    "datasetfiles.sort()\n",
    "datasetpath_img = \"./dataset/img/\"\n",
    "\n",
    "print(\"preparing for dataset\")\n",
    "start = time.time()\n",
    "dataset = []\n",
    "\n",
    "# calculate the Hue and Saturation histogram of the dataset images in HSV color space\n",
    "for i in range(len(datasetfiles)):\n",
    "    label, name = datasetfiles[i].split(\".\")[0].split(\"_\")\n",
    "    img = cv2.imread(datasetpath_img + name + \".JPG\")\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.imread(datasetpath + datasetfiles[i], cv2.IMREAD_GRAYSCALE)\n",
    "    hist = cv2.calcHist([img_hsv], [0,1], mask, [180,256], [0,180,0,256])\n",
    "#     hist = cv2.calcHist([img], [0,1,2], mask, [256,256,256], [0,256,0,256,0,256])\n",
    "    cv2.normalize(hist, hist, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX);\n",
    "    info = {\"label\": label, \"hist\": hist}\n",
    "    dataset.append(info)\n",
    "\n",
    "end = time.time()\n",
    "print(\"preparing time:\", end-start)\n",
    "\n",
    "VI = [{\"vi\": \"Gray\", \"thresh\": 4}, \n",
    "      {\"vi\": \"CLAHE\", \"thresh\": 9}, \n",
    "      {\"vi\": \"TGI\", \"thresh\": 4}, \n",
    "      {\"vi\": \"VARI\", \"thresh\": 2}]\n",
    "\n",
    "vi_seedlings = []\n",
    "img_area = 6000*4000\n",
    "\n",
    "for i in range(len(inputfiles)):\n",
    "    start = time.time()\n",
    "    img = cv2.imread(inputpath + inputfiles[i])\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    name = inputfiles[i][:8]\n",
    "    print(\"input:\", name)  \n",
    "\n",
    "    ## generating the preprocessing images\n",
    "    vi_start = time.time()\n",
    "    IMG = []\n",
    "\n",
    "    # preprocessing image 1: convert the image into grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # preprocessing image 2: enhance the grayscale image using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit = 5) \n",
    "    Gray = clahe.apply(gray)\n",
    "\n",
    "    B, G, R = cv2.split(img)\n",
    "    # preprocessing image 3: compute the vegetation index image by TGI (Triangular Greenness Index)\n",
    "    TGI = calcTGI(B, G, R)\n",
    "    TGI = complement(TGI)\n",
    "    # preprocessing image 4: compute the vegetation index image by VARI (Visible Atmospherically Resistant Index)\n",
    "    VARI = calcVARI(B, G, R)\n",
    "\n",
    "    IMG.append(gray)\n",
    "    IMG.append(Gray)\n",
    "    IMG.append(TGI)\n",
    "    IMG.append(VARI)\n",
    "\n",
    "    vi_end = time.time()\n",
    "    print(\"Generating preprocessing imgs, time:\", vi_end-vi_start)   \n",
    "    \n",
    "    ## generating the superpixel image by SLIC (Simple Linear Iterative Clustering)\n",
    "    start_slic = time.time()\n",
    "    img_rgb = cv2.medianBlur(img_rgb, 5)\n",
    "    segments_slic = slic(img_rgb, n_segments = 1500, compactness = 15)\n",
    "    slic_id = np.unique(segments_slic)\n",
    "    print(\"# of superpixels:\", len(slic_id))\n",
    "    end_slic = time.time()\n",
    "\n",
    "    # coloring each superpixel on the image\n",
    "    colorimg = label2rgb(segments_slic, image=img, alpha=0.5)\n",
    "    colorimg = mark_boundaries(colorimg, segments_slic, color=(0, 1, 1), outline_color=(0, 1, 1))\n",
    "    colorimg = img_as_ubyte(colorimg)\n",
    "    cv2.imwrite(outputpath + \"slic/\" + name + \"_n1500_color.jpg\", colorimg)\n",
    "    print(\"SLIC time:\", end_slic-start_slic)\n",
    "\n",
    "    # By computing the RAG (Region Adjacency Graph) using mean colors,    \n",
    "    # if the mean colors of neighboring superpixels are closed enough to each other, the superpixels will be merged into one.\n",
    "    thresh = 15\n",
    "    print(\"start merging the superpixels if the mean colors between them are closed enough.\")\n",
    "    start_rag = time.time()\n",
    "    g = graph.rag_mean_color(img_rgb, segments_slic)\n",
    "    segments_slic2 = graph.cut_threshold(segments_slic, g, thresh)\n",
    "    slic_id2 = np.unique(segments_slic2)\n",
    "    print(\"# of superpixels after rag thresholding:\", len(slic_id2))  \n",
    "    \n",
    "    # after merging step, coloring each superpixel on the image\n",
    "    colorimg = label2rgb(segments_slic2, image=img, alpha=0.5)\n",
    "    colorimg = mark_boundaries(colorimg, segments_slic2, color=(0, 1, 1), outline_color=(0, 1, 1))\n",
    "    colorimg = img_as_ubyte(colorimg)\n",
    "    cv2.imwrite(outputpath + \"slic_merge/\" + name + \"_n1500_color_rag_t\" + str(thresh) +\".jpg\", colorimg)\n",
    "    end_rag = time.time()\n",
    "    print(\"merging time:\", end_rag-start_rag)\n",
    "    \n",
    "    ## labeling each superpixel as paddy or not paddy with 3-NN classification\n",
    "    mask_paddy = np.zeros(img.shape[:2], dtype = \"uint8\")\n",
    "    print(\"start extracting paddy field.\")\n",
    "    start_label = time.time()\n",
    "    for index in slic_id2:\n",
    "        area = np.count_nonzero(segments_slic2 == index)\n",
    "        # calculating the proportion of the superpixel area on the img area\n",
    "        proportion = area / img_area\n",
    "        if proportion < 0.01:\n",
    "            continue\n",
    "        \n",
    "        slic_ID = name + \"_\" + str(index)\n",
    "        slic_mask = np.zeros(img.shape[:2], dtype = \"uint8\")\n",
    "        slic_mask[segments_slic2 == index] = 255\n",
    "\n",
    "        hist_slic = cv2.calcHist([img_hsv], [0,1], slic_mask, [180,256], [0,180,0,256])\n",
    "        cv2.normalize(hist_slic, hist_slic, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX);\n",
    "        # checking the superpixel is the most similar wiht which label the dataset image is.\n",
    "        comparehist = []\n",
    "        for data in dataset:\n",
    "            correl = cv2.compareHist(hist_slic, data[\"hist\"], cv2.HISTCMP_CORREL)\n",
    "            info = {\"label\": data[\"label\"], \"correl\": correl}\n",
    "            comparehist.append(info)\n",
    "            \n",
    "        compare = sorted(comparehist, key = lambda item : item[\"correl\"], reverse = True)\n",
    "        paddy_label = 0\n",
    "        for i in range(3):\n",
    "            if compare[i][\"correl\"] < 0:\n",
    "                continue\n",
    "            if compare[i][\"label\"]==\"paddy\":\n",
    "                paddy_label += 1\n",
    "\n",
    "        # if paddy label is more than 1 in the labels with top 3 highest correlation, \n",
    "        # than the superpixel will be considered as paddy field.\n",
    "        # The final mask_paddy is the mask of paddy field.\n",
    "        if paddy_label > 1:\n",
    "            mask_paddy = cv2.bitwise_or(mask_paddy, slic_mask)\n",
    "    \n",
    "    end_label = time.time()\n",
    "    print(\"label time:\", end_label-start_label)\n",
    "\n",
    "    # morphology on the mask_paddy\n",
    "    test = time.time()\n",
    "    kernel = np.ones((45,45),np.uint8)\n",
    "    opening = cv2.morphologyEx(mask_paddy, cv2.MORPH_OPEN, kernel, iterations=5)\n",
    "    mask_convex = morphology.convex_hull_object(opening)\n",
    "    mask_convex = 255*mask_convex\n",
    "    mask_convex = mask_convex.astype(np.uint8)\n",
    "    test = time.time() - test\n",
    "    print(\"morphology time:\", test)\n",
    "\n",
    "    paddy = cv2.bitwise_and(img, img, mask = mask_convex)\n",
    "\n",
    "    # save the mask image\n",
    "    cv2.imwrite(outputpath + \"paddy/\" + name + \"_paddy.jpg\", paddy)\n",
    "    cv2.imwrite(outputpath + \"paddy_mask/\" + name + \"_mask.jpg\", mask_convex)\n",
    "    mask = mask_convex\n",
    "\n",
    "    ## applying blob detection on the preprocessing images with mask_paddy\n",
    "    print(\"start blob detection\")\n",
    "    for item in VI:\n",
    "        seedlings = []\n",
    "        vid = VI.index(item)\n",
    "        vi = item[\"vi\"]\n",
    "        img_vi = IMG[vid]\n",
    "        \n",
    "        cv2.imwrite(outputpath + \"preprocess/\" + name + \"_\" + vi + \".jpg\", img_vi)\n",
    "        \n",
    "        paddy_vi = cv2.bitwise_and(img_vi, img_vi, mask = mask)\n",
    "        \n",
    "        thresh = item[\"thresh\"]\n",
    "        print(vi, \"threshStep =\", thresh)\n",
    "        \n",
    "        # Set up the detector with default parameters.\n",
    "        parameters = cv2.SimpleBlobDetector_Params()\n",
    "        # We detect the darker blobers, so the ExG image should be inversed\n",
    "        #darker blobers: blobColor = 0; lighter blobers: blobColor=255  \n",
    "        parameters.filterByColor = True\n",
    "        parameters.blobColor = 0\n",
    "        # setting minArea  = 100 will filter out all the blobs that have less then 100 pixels\n",
    "        parameters.filterByArea = True\n",
    "        parameters.minArea = 15\n",
    "        parameters.filterByCircularity = True\n",
    "        parameters.minCircularity = 0.1\n",
    "        parameters.filterByConvexity = True\n",
    "        parameters.minConvexity = 0.87\n",
    "        parameters.thresholdStep = thresh\n",
    "        \n",
    "        # setting the blob detector\n",
    "        detector = cv2.SimpleBlobDetector_create(parameters)\n",
    "        \n",
    "        start_blob = time.time()\n",
    "\n",
    "        keypoints_blob = detector.detect(paddy_vi)\n",
    "        paddy_blob = img.copy()\n",
    "        paddy_blob = cv2.drawKeypoints(paddy_blob, keypoints_blob, np.array([]), (255,0,0), v2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        kps_blob = len(keypoints_blob)\n",
    "        print(\"kps_\" + vi + \"=\", kps_blob)\n",
    "        \n",
    "        cv2.imwrite(outputpath + \"seedlings/img/\" + name + \"_\" + vi + \"_blob.jpg\", paddy_blob)\n",
    "        info = {'fileName': name, 'VI': vi, 'keypoints': kps_blob}\n",
    "        vi_seedlings.append(info)\n",
    "        \n",
    "        for keypt in keypoints_blob:\n",
    "            info = {'keypoints': str(keypt.pt)}\n",
    "            seedlings.append(info)\n",
    "        \n",
    "        ## write the positions of the keypoints in a csv file\n",
    "        csvpath = outputpath + \"seedlings/position/\"\n",
    "        csvname = name + \"_\" + vi + '.csv'\n",
    "        print(\"write\", csvname)\n",
    "        with open(csvpath + csvname, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['keypoints']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for i in seedlings:\n",
    "                writer.writerow(i)\n",
    "        \n",
    "        end_blob = time.time()\n",
    "        print(vi + \" blob time:\", end_blob-start_blob)\n",
    "        \n",
    "\n",
    "## record the quantities of detected seedlings in each detection result\n",
    "with open(outputpath + \"seedlings/seedlings.csv\", 'w', newline='') as csvfile:\n",
    "    fieldnames = ['fileName', 'VI', 'keypoints']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in vi_seedlings:\n",
    "        writer.writerow(i)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}